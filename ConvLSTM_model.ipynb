{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aa68fa-6910-4f0f-a2e8-a499401ddbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentinelsat\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade attrs\n",
    "!pip install h5netcdf\n",
    "!pip install netCDF4\n",
    "!pip install scipy\n",
    "!pip uninstall xarray -y\n",
    "!pip install xarray\n",
    "!pip install matplotlib\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu\n",
    "!pip install -q -U keras-tuner\n",
    "!conda install -c conda-forge harp -y\n",
    "\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "from glob import iglob\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d0bd4-8d87-4471-9723-38afdb96dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "from glob import iglob\n",
    "from os.path import join\n",
    "import os\n",
    "\n",
    "no_of_samples = 1529\n",
    "channels = 2\n",
    "image_dim = 16\n",
    "\n",
    "\n",
    "input_length = 10\n",
    "output_length = 5\n",
    "\n",
    "product_path_NO2 = \"Dataset_NO2_Processed/\"\n",
    "product_path_LST = \"Dataset_LST_Processed/\"\n",
    "\n",
    "input_files_NO2 = sorted(list(iglob(join(product_path_NO2, '*NO2*.npy'), recursive=False)))\n",
    "input_files_LST = sorted(list(iglob(join(product_path_LST, '*LST*.npy'), recursive=False)))\n",
    "\n",
    "no_of_samples = len(input_files_NO2)\n",
    "no_train_samples = int(no_of_samples*0.8)\n",
    "no_test_samples = no_of_samples - no_train_samples\n",
    "print(\"Number of samples: \", no_of_samples)\n",
    "\n",
    "train_samples = np.zeros(shape=(no_train_samples,image_dim,image_dim,channels))\n",
    "test_samples = np.zeros(shape=(no_test_samples,image_dim,image_dim,channels))\n",
    "count = 0\n",
    "\n",
    "#Stack the NO2 and LST data in separate channels of the same frame.\n",
    "for NO2 in input_files_NO2:\n",
    "    image_no2 = np.load(NO2)\n",
    "    #21-29 for new 15-23 for old\n",
    "    image_LST = np.load(join(product_path_LST, NO2[(len(product_path_NO2)+21):(len(product_path_NO2)+29)]) + \"_LST.npy\")\n",
    "    \n",
    "    if image_no2.shape == (1,image_dim,image_dim):\n",
    "        image_no2 = image_no2.reshape(image_dim,image_dim,1)\n",
    "        image_LST = image_LST.reshape(image_dim,image_dim,1)\n",
    "        \n",
    "        if count < no_train_samples:\n",
    "            train_samples[count] = (np.concatenate((image_no2, image_LST), axis=2))\n",
    "        else:\n",
    "            test_samples[count-no_train_samples] = (np.concatenate((image_no2, image_LST), axis=2))\n",
    "        \n",
    "        \n",
    "    count = count + 1\n",
    "    \n",
    "train_samples.clip(min=0, out=train_samples)\n",
    "test_samples.clip(min=0, out=test_samples)\n",
    "\n",
    "# Computing statistics for normalisation.\n",
    "min = np.nanmin(train_samples, axis = (0,1,2))\n",
    "max = np.nanmax(train_samples, axis = (0,1,2))\n",
    "mean = np.nanmean(train_samples, axis = (0,1,2))\n",
    "std = np.nanstd(train_samples, axis = (0,1,2))\n",
    "\n",
    "train_samples = train_samples - min\n",
    "train_samples = train_samples/(max-min)\n",
    "test_samples = test_samples - min\n",
    "test_samples = test_samples/(max-min)\n",
    "\n",
    "train_samples = np.nan_to_num(train_samples)\n",
    "test_samples = np.nan_to_num(test_samples)\n",
    "\n",
    "train_samples = np.clip(train_samples, 0, 1, out=train_samples)\n",
    "test_samples = np.clip(test_samples, 0, 1, out=test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24830a18-bd33-4f65-9fbd-89c3f8f168c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for Figure 4.3\n",
    "#plt.hist(train_samples[:,:,:,0].reshape(len(train_samples),-1))\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d9baf8-0eb5-4939-bd16-e4b7883d4e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4D tensor to 5D tensor\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Create model inputs and corresponding labels using bundles of sequential data.\n",
    "# The following code in this cell has been adapted from the work of Muthukumar et. al.\n",
    "train_bundles = np.empty((no_train_samples-input_length,input_length,image_dim,image_dim,channels))\n",
    "for i in range(no_train_samples-input_length):\n",
    "    bundle = np.array([train_samples[i + k] for k in range(input_length)])\n",
    "    train_bundles[i] = bundle\n",
    "no_train_samples = train_bundles.shape[0]\n",
    "    \n",
    "test_bundles = np.empty((no_test_samples-input_length,input_length,image_dim,image_dim,channels))\n",
    "for i in range(no_test_samples-input_length):\n",
    "    bundle = np.array([test_samples[i + k] for k in range(input_length)])\n",
    "    test_bundles[i] = bundle\n",
    "no_test_samples = test_bundles.shape[0]\n",
    "\n",
    "X_train = train_bundles[:no_train_samples-(input_length)]\n",
    "X_val = test_bundles[:int(no_test_samples*0.5)]\n",
    "X_test = test_bundles[int(no_test_samples*0.5)+input_length:no_test_samples-(input_length)]\n",
    "\n",
    "y_train = np.expand_dims(train_bundles[input_length:,:output_length,:,:,0],-1)\n",
    "y_val = np.expand_dims(test_bundles[input_length:int(no_test_samples*0.5)+input_length,:output_length,:,:,0],-1)\n",
    "y_test = np.expand_dims(test_bundles[int(no_test_samples*0.5)+2*input_length:,:output_length,:,:,0],-1)\n",
    "\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=7)\n",
    "\n",
    "print(X_train.shape, \"X_train shape\")\n",
    "print(X_val.shape, \"X_val shape\")\n",
    "print(X_test.shape, \"X_test shape\")\n",
    "\n",
    "print(y_train.shape, \"y_train shape\")\n",
    "print(y_val.shape, \"y_val shape\")\n",
    "print(y_test.shape, \"y_test shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af326ee-1285-4985-b403-e18d6577dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import ConvLSTM2D, Input\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.backend import expand_dims, repeat_elements\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "# Implementation of the shrinkage loss function.\n",
    "def shrinkage_loss(y_true, y_pred):\n",
    " \n",
    "    error = tf.subtract(y_pred, y_true)\n",
    "    squared_error = K.square(error) \n",
    "    \n",
    "    a = 10.0\n",
    "    c = 0.1\n",
    "    \n",
    "    shrinkage_loss = (squared_error/(1 + K.exp(a * (c - error))))\n",
    "                \n",
    "    loss = tf.reduce_mean(shrinkage_loss, axis=(1,2,3,4))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Implementation of the shrinkage version of the mean absolute loss.\n",
    "def shrinkage_absolute_loss(y_true, y_pred):\n",
    " \n",
    "    error = y_pred - y_true\n",
    "    squared_error = K.abs(error) \n",
    "    \n",
    "    a = 10.0\n",
    "    c = 0.3\n",
    "    \n",
    "    shrinkage_loss = squared_error/(1 + K.exp(a * (c - error)))\n",
    "    \n",
    "    loss = K.mean(shrinkage_loss, axis=(1,2,3,4))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def repeatV(x):\n",
    "    return repeat_elements(expand_dims(x, axis=1), output_length, 1)\n",
    "\n",
    "# Implementation of the Convolutional LSTM model.\n",
    "inputs = Input(shape=(input_length, image_dim, image_dim, channels))\n",
    "enc_layer_1 = ConvLSTM2D(filters=32, kernel_size=7,\n",
    "                   input_shape=(input_length, image_dim, image_dim, channels),\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(inputs)\n",
    "enc_batch_norm_1 = BatchNormalization()(enc_layer_1)\n",
    "\n",
    "enc_layer_2 = ConvLSTM2D(filters=64, kernel_size=7,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(enc_batch_norm_1)\n",
    "enc_batch_norm_2 = BatchNormalization()(enc_layer_2)\n",
    "\n",
    "enc_layer_3 = ConvLSTM2D(filters=128, kernel_size=9,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(enc_batch_norm_2)\n",
    "enc_batch_norm_3 = BatchNormalization()(enc_layer_3)\n",
    "\n",
    "enc_layer_4 = ConvLSTM2D(filters=128, kernel_size=9,\n",
    "                   padding='same', return_sequences=False, data_format='channels_last')(enc_batch_norm_3)\n",
    "enc_batch_norm_4 = BatchNormalization()(enc_layer_4)\n",
    "\n",
    "repeat = Lambda(repeatV)(enc_batch_norm_4)\n",
    "\n",
    "dec_layer_1 = ConvLSTM2D(filters=128, kernel_size=11,\n",
    "                   input_shape=(output_length, image_dim, image_dim, channels),\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(repeat)\n",
    "dec_batch_norm_1 = BatchNormalization()(dec_layer_1)\n",
    "\n",
    "dec_layer_2 = ConvLSTM2D(filters=128, kernel_size=9,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(dec_batch_norm_1)\n",
    "dec_batch_norm_2 = BatchNormalization()(dec_layer_2)\n",
    "\n",
    "dec_layer_3 = ConvLSTM2D(filters=64, kernel_size=9,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(dec_batch_norm_2)\n",
    "dec_batch_norm_3 = BatchNormalization()(dec_layer_3)\n",
    "\n",
    "dec_layer_4 = ConvLSTM2D(filters=32, kernel_size=7,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(dec_batch_norm_3)\n",
    "dec_batch_norm_4 = BatchNormalization()(dec_layer_4)\n",
    "\n",
    "y = Conv2D(filters=1, kernel_size=9,\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last')(dec_batch_norm_4)\n",
    "\n",
    "seq = Model(inputs, y)\n",
    "\n",
    "# Different loss functions, e.g. shrinkage_loss, \"mean_squared_error\", etc., can be used to compile the model.\n",
    "seq.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.90, beta_2=0.999, amsgrad=False), metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7174857-20f9-4982-aa07-9408dac0d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was used to set up the hyperparameter tuner.\n",
    "\n",
    "# !pip install keras\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-gpu\n",
    "# !pip install -q -U keras-tuner\n",
    "# import keras_tuner as kt\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# import keras\n",
    "# from keras.models import Model\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "# from keras.layers import ConvLSTM2D, Input\n",
    "# from keras.layers import RepeatVector\n",
    "# from keras.layers import BatchNormalization\n",
    "\n",
    "# from keras.backend import expand_dims, repeat_elements\n",
    "# from keras.layers import Lambda\n",
    "\n",
    "# import keras.backend as K\n",
    "\n",
    "# def shrinkage_loss(y_true, y_pred):\n",
    " \n",
    "#     error = y_pred - y_true\n",
    "#     squared_error = K.square(y_pred - y_true)\n",
    "    \n",
    "#     a = 10.0\n",
    "#     c = 0.1\n",
    "    \n",
    "#     shrinkage_loss = squared_error/(1 + K.exp(a * (c - error)))\n",
    "                \n",
    "#     loss = K.mean(shrinkage_loss, axis=(1,2,3,4))\n",
    "    \n",
    "#     return loss\n",
    "\n",
    "# def repeatV(x):\n",
    "#     return repeat_elements(expand_dims(x, axis=1), output_length, 1)\n",
    "\n",
    "# def model_builder_enc_dec(hp):\n",
    "    \n",
    "#     inputs = Input(shape=(input_length, image_dim, image_dim, channels))\n",
    "#     layer_input = inputs\n",
    "#     num_enc_layers = hp.Int('enc_layers', 1, 8)\n",
    "#     num_dec_layers = hp.Int('dec_layers', 1, 8)\n",
    "#     for i in range(num_enc_layers):\n",
    "#         if(i == num_enc_layers-1):\n",
    "#             return_sequence = False\n",
    "#         else:\n",
    "#             return_sequence = True\n",
    "    \n",
    "#         layer = ConvLSTM2D(filters=hp.Choice(f'filters_enc_{i}', [8,16,32,64,128]), kernel_size=hp.Int(f'kernel_enc_{i}', min_value=3, max_value=11, step=2),\n",
    "#                            input_shape=(input_length, image_dim, image_dim, channels),\n",
    "#                            padding='same', return_sequences=return_sequence, data_format='channels_last')(layer_input)\n",
    "#         batch_norm = BatchNormalization()(layer)\n",
    "        \n",
    "#         layer_input = batch_norm\n",
    "\n",
    "#     repeat = Lambda(repeatV)(layer_input)\n",
    "    \n",
    "#     layer_input = repeat\n",
    "    \n",
    "#     for i in range(num_enc_layers):\n",
    "#         layer = ConvLSTM2D(filters=hp.Choice(f'filters_dec_{i}', [8,16,32,64,128]), kernel_size=hp.Int(f'kernel_dec_{i}', min_value=3, max_value=11, step=2),\n",
    "#                            input_shape=(input_length, image_dim, image_dim, channels),\n",
    "#                            padding='same', return_sequences=True, data_format='channels_last')(layer_input)\n",
    "#         batch_norm = BatchNormalization()(layer)\n",
    "        \n",
    "#         layer_input = batch_norm\n",
    "\n",
    "#     kernel = hp.Int('kernel', min_value=3, max_value=11, step=2)\n",
    "        \n",
    "#     y = Conv2D(filters=1, kernel_size=kernel,\n",
    "#                    activation='sigmoid',\n",
    "#                    padding='same', data_format='channels_last')(layer_input)\n",
    "    \n",
    "#     seq = Model(inputs, y)\n",
    "    \n",
    "#     learning_rate = hp.Choice('learning_rate', [0.005, 0.001, 0.0005, 0.0001, 0.00005])\n",
    "#     beta_1 = hp.Choice('beta_1', [0.7, 0.8, 0.9, 0.999])\n",
    "#     beta_2 = hp.Choice('beta_2', [0.7, 0.8, 0.9, 0.999])\n",
    "    \n",
    "#     seq.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.Adam(learning_rate=learning_rate, beta_1=beta_1, beta_2=beta_2, amsgrad=False), metrics=[\"mean_absolute_error\"])\n",
    "    \n",
    "#     return seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd64ce3-7a0a-41a7-a324-2343e5d1c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code was used to run the hyperparameter tuner.\n",
    "\n",
    "# tuner = kt.Hyperband(model_builder_enc_dec,\n",
    "#                      objective=kt.Objective(\"val_mean_absolute_error\", direction=\"min\"),\n",
    "#                      max_epochs=40,\n",
    "#                      factor=3,\n",
    "#                      directory='tuner',\n",
    "#                      project_name='ConvLSTM_Tune')\n",
    "\n",
    "# tuner.search(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
    "# best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
