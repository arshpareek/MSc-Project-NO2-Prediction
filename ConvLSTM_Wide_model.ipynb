{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77beabf-07f1-4a4f-b25a-677d8e5e17e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentinelsat\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade attrs\n",
    "!pip install h5netcdf\n",
    "!pip install netCDF4\n",
    "!pip install scipy\n",
    "!pip uninstall xarray -y\n",
    "!pip install xarray\n",
    "!pip install matplotlib\n",
    "!conda install -c conda-forge harp -y\n",
    "\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "from glob import iglob\n",
    "import harp\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f334b1b-fd45-4f2a-9897-0d88dc21c1f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "from glob import iglob\n",
    "from os.path import join\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "!pip install scikit-image\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "channels = 2\n",
    "image_dim = 64\n",
    "output_image_dim = 16\n",
    "input_length = 10\n",
    "output_length = 5\n",
    "\n",
    "\n",
    "product_path_NO2 = \"Dataset_NO2_Wide_Processed/\"\n",
    "product_path_LST = \"Dataset_LST_Wide_Processed/\"\n",
    "\n",
    "input_files_NO2 = sorted(list(iglob(join(product_path_NO2, '*NO2*.npy'), recursive=False)))\n",
    "input_files_LST = sorted(list(iglob(join(product_path_LST, '*LST*.npy'), recursive=False)))\n",
    "\n",
    "\n",
    "no_of_samples = len(input_files_NO2)\n",
    "no_train_samples = int(no_of_samples*0.8)\n",
    "no_test_samples = no_of_samples - no_train_samples\n",
    "\n",
    "train_samples = np.zeros(shape=(no_train_samples,image_dim,image_dim,channels))\n",
    "test_samples = np.zeros(shape=(no_test_samples,image_dim,image_dim,channels))\n",
    "count = 0\n",
    "\n",
    "#Stack the NO2 and LST data in separate channels of the same frame.\n",
    "for NO2 in input_files_NO2:\n",
    "    image_no2 = np.load(NO2)\n",
    "    \n",
    "    image_LST = np.load(join(product_path_LST, NO2[(len(product_path_NO2)+21):(len(product_path_NO2)+29)]) + \"_LST.npy\")\n",
    "    \n",
    "    if image_no2.shape == (1,82,81):\n",
    "        image_no2 = resize(image_no2.reshape(82,81,1), (64, 64, 1))\n",
    "        image_LST = resize(image_LST.reshape(82,82,1), (64, 64, 1))\n",
    "        \n",
    "        if count < no_train_samples:\n",
    "            train_samples[count] = (np.concatenate((image_no2, image_LST), axis=2))\n",
    "        else:\n",
    "            test_samples[count-no_train_samples] = (np.concatenate((image_no2, image_LST), axis=2))\n",
    "        \n",
    "    else:\n",
    "        print(\"Wrong Input Dimension\")\n",
    "    count = count + 1\n",
    "    \n",
    "train_samples.clip(min=0, out=train_samples)\n",
    "test_samples.clip(min=0, out=test_samples)\n",
    "\n",
    "# Computing statistics for normalisation.\n",
    "min = np.nanmin(train_samples, axis = (0,1,2))\n",
    "max = np.nanmax(train_samples, axis = (0,1,2))\n",
    "\n",
    "train_samples = train_samples - min\n",
    "train_samples = train_samples/(max-min)\n",
    "test_samples = test_samples - min\n",
    "test_samples = test_samples/(max-min)\n",
    "\n",
    "train_samples = np.nan_to_num(train_samples)\n",
    "test_samples = np.nan_to_num(test_samples)\n",
    "\n",
    "train_samples = np.clip(train_samples, 0, 1, out=train_samples)\n",
    "test_samples = np.clip(test_samples, 0, 1, out=test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c7e885-32dd-42f7-8e85-de8ff004b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    n,s,y,x,c = img.shape\n",
    "    startx = x//2 - cropx//2\n",
    "    starty = y//2 - cropy//2    \n",
    "    return img[:, :, starty:starty+cropy, startx:startx+cropx, :]\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Create model inputs and corresponding labels using bundles of sequential data.\n",
    "# The following code in this cell has been adapted from the work of Muthukumar et. al.\n",
    "train_bundles = np.empty((no_train_samples-input_length,input_length,image_dim,image_dim,channels))\n",
    "for i in range(no_train_samples-input_length):\n",
    "    bundle = np.array([train_samples[i + k] for k in range(input_length)])\n",
    "    train_bundles[i] = bundle\n",
    "no_train_samples = train_bundles.shape[0]\n",
    "    \n",
    "test_bundles = np.empty((no_test_samples-input_length,input_length,image_dim,image_dim,channels))\n",
    "for i in range(no_test_samples-input_length):\n",
    "    bundle = np.array([test_samples[i + k] for k in range(input_length)])\n",
    "    test_bundles[i] = bundle\n",
    "no_test_samples = test_bundles.shape[0]\n",
    "\n",
    "X_train = train_bundles[:no_train_samples-(input_length)]\n",
    "X_val = test_bundles[:int(no_test_samples*0.5)]\n",
    "X_test = test_bundles[int(no_test_samples*0.5)+input_length:no_test_samples-(input_length)]\n",
    "\n",
    "y_train = crop_center(np.expand_dims(train_bundles[input_length:,:output_length,:,:,0],-1), output_image_dim, output_image_dim)\n",
    "y_val = crop_center(np.expand_dims(test_bundles[input_length:int(no_test_samples*0.5)+input_length,:output_length,:,:,0],-1), output_image_dim, output_image_dim)\n",
    "y_test = crop_center(np.expand_dims(test_bundles[int(no_test_samples*0.5)+2*input_length:,:output_length,:,:,0],-1), output_image_dim, output_image_dim)\n",
    "\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=7)\n",
    "\n",
    "print(X_train.shape, \"X_train shape\")\n",
    "print(X_val.shape, \"X_val shape\")\n",
    "print(X_test.shape, \"X_test shape\")\n",
    "\n",
    "print(y_train.shape, \"y_train shape\")\n",
    "print(y_val.shape, \"y_val shape\")\n",
    "print(y_test.shape, \"y_test shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bebf0ee-aaaa-4477-b7d1-5d9902ad0271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import ConvLSTM2D, Input, AveragePooling2D\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from keras.backend import expand_dims, repeat_elements\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "# Implementation of the shrinkage loss function.\n",
    "def shrinkage_loss(y_true, y_pred):\n",
    " \n",
    "    error = tf.subtract(y_pred, y_true)\n",
    "    squared_error = K.square(error) \n",
    "    \n",
    "    a = 10.0\n",
    "    c = 0.1\n",
    "    \n",
    "    shrinkage_loss = (squared_error/(1 + K.exp(a * (c - error))))\n",
    "                \n",
    "    loss = tf.reduce_mean(shrinkage_loss, axis=(1,2,3,4))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def repeatV(x):\n",
    "    return repeat_elements(expand_dims(x, axis=1), output_length, 1)\n",
    "\n",
    "# Implementation of the Convolutional LSTM model for wide inputs.\n",
    "inputs = Input(shape=(input_length, image_dim, image_dim, channels))\n",
    "enc_layer_1 = ConvLSTM2D(filters=32, kernel_size=11,\n",
    "                   input_shape=(input_length, image_dim, image_dim, channels),\n",
    "                   padding='valid', return_sequences=True, data_format='channels_last')(inputs)\n",
    "enc_batch_norm_1 = BatchNormalization()(enc_layer_1)\n",
    "\n",
    "enc_layer_2 = ConvLSTM2D(filters=128, kernel_size=9,\n",
    "                   padding='valid', return_sequences=True, data_format='channels_last')(enc_batch_norm_1)\n",
    "enc_batch_norm_2 = BatchNormalization()(enc_layer_2)\n",
    "\n",
    "enc_layer_3 = ConvLSTM2D(filters=8, kernel_size=9,\n",
    "                   padding='valid', return_sequences=True, data_format='channels_last')(enc_batch_norm_2)\n",
    "enc_batch_norm_3 = BatchNormalization()(enc_layer_3)\n",
    "\n",
    "enc_layer_4 = ConvLSTM2D(filters=32, kernel_size=7,\n",
    "                   padding='valid', return_sequences=False, data_format='channels_last')(enc_batch_norm_3)\n",
    "enc_batch_norm_4 = BatchNormalization()(enc_layer_4)\n",
    "\n",
    "pooling_layer = AveragePooling2D(pool_size=(2, 2), strides=2)(enc_batch_norm_4)\n",
    "\n",
    "repeat = Lambda(repeatV)(pooling_layer)\n",
    "\n",
    "dec_layer_1 = ConvLSTM2D(filters=32, kernel_size=11,\n",
    "                   input_shape=(output_length, output_image_dim, output_image_dim, channels),\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(repeat)\n",
    "dec_batch_norm_1 = BatchNormalization()(dec_layer_1)\n",
    "\n",
    "dec_layer_2 = ConvLSTM2D(filters=128, kernel_size=9,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(dec_batch_norm_1)\n",
    "dec_batch_norm_2 = BatchNormalization()(dec_layer_2)\n",
    "\n",
    "dec_layer_3 = ConvLSTM2D(filters=128, kernel_size=7,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(dec_batch_norm_2)\n",
    "dec_batch_norm_3 = BatchNormalization()(dec_layer_3)\n",
    "\n",
    "dec_layer_4 = ConvLSTM2D(filters=64, kernel_size=5,\n",
    "                   padding='same', return_sequences=True, data_format='channels_last')(dec_batch_norm_3)\n",
    "dec_batch_norm_4 = BatchNormalization()(dec_layer_4)\n",
    "\n",
    "y = Conv2D(filters=1, kernel_size=9,\n",
    "               activation='sigmoid',\n",
    "               padding='same', data_format='channels_last')(dec_batch_norm_4)\n",
    "\n",
    "seq = Model(inputs, y)\n",
    "\n",
    "# Different loss functions, e.g. shrinkage_loss, \"mean_squared_error\", etc., can be used to compile the model.\n",
    "seq.compile(loss=shrinkage_loss, optimizer=keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.95, beta_2=0.999, amsgrad=False), metrics=[\"mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993eca5-1f2a-49bf-97fa-1c58f500708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model.\n",
    "\n",
    "model_path = 'saved_models/model_wide'\n",
    "\n",
    "json_file = open(model_path + '.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "seq = keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "seq.load_weights(model_path + \".h5\")\n",
    "print(\"Model Loaded\")\n",
    "seq.compile(loss=shrinkage_loss, optimizer=keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999, amsgrad=False), metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "# Use following code to train model from scratch.\n",
    "#seq.summary()\n",
    "#history = seq.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val))\n",
    "#Y_hat = seq.predict(X_test, verbose=0)\n",
    "#print(Y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75776747-e3e2-403e-ac28-40e20f3efa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for saving model and weights.\n",
    "# model_json = seq.to_json()\n",
    "# with open(\"model.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json)\n",
    "    \n",
    "# # Save weights to HDF5\n",
    "# seq.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4d3f7-2f2b-4a92-9ee6-2c9e73675a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following visualization code in this cell is taken from Muthukumar et. al's work.\n",
    "# Randomly visualizes frame sequences from the test set.\n",
    "def visualization(y, y_hat, n_slots):\n",
    "    \n",
    "    import random\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    length = y_hat.shape[0]\n",
    "    random_ind = [x for x in range(0,n_slots)]\n",
    "    setCount = 1;\n",
    "    for ind in random_ind:\n",
    "        setCount = setCount+1;\n",
    "        fig, (ax1, ax2)= plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5))\n",
    "\n",
    "        y_pre = y_hat[ind,0,:,:,0]\n",
    "        ax1.imshow(y_pre)\n",
    "\n",
    "        y_truth = y[ind,0,:,:,0]\n",
    "        ax2.imshow(y_truth)\n",
    "\n",
    "        plt.text(2, -0.8, 'Ground truth Frame 1', fontsize=13)\n",
    "    \n",
    "        fig, (ax1, ax2)= plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5))\n",
    "        \n",
    "        y_pre = y_hat[ind,1,:,:,0]\n",
    "        ax1.imshow(y_pre)\n",
    "        \n",
    "        y_truth = y[ind,1,:,:,0]\n",
    "        ax2.imshow(y_truth)\n",
    "\n",
    "        plt.text(2, -0.8, 'Ground truth Frame 2', fontsize=13)\n",
    "    \n",
    "    \n",
    "        fig, (ax1, ax2)= plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5))\n",
    "        \n",
    "        y_pre = y_hat[ind,2,:,:,0]\n",
    "        ax1.imshow(y_pre)\n",
    "\n",
    "        y_truth = y[ind,2,:,:,0]\n",
    "        ax2.imshow(y_truth)\n",
    "\n",
    "        plt.text(2, -0.8, 'Ground truth Frame 3', fontsize=13)\n",
    "    \n",
    "        fig, (ax1, ax2)= plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5))\n",
    "\n",
    "        y_pre = y_hat[ind,3,:,:,0]\n",
    "        ax1.imshow(y_pre)\n",
    "\n",
    "        y_truth = y[ind,3,:,:,0]\n",
    "        ax2.imshow(y_truth)\n",
    "\n",
    "        plt.text(2, -0.8, 'Ground truth Frame 4', fontsize=13)\n",
    "    \n",
    "        fig, (ax1, ax2)= plt.subplots(1, 2, sharey=True, sharex=True, figsize=(10, 5))\n",
    "\n",
    "        y_pre = y_hat[ind,4,:,:,0]\n",
    "        ax1.imshow(y_pre)\n",
    "\n",
    "        y_truth = y[ind,4,:,:,0]\n",
    "        ax2.imshow(y_truth)\n",
    "\n",
    "        plt.text(2, -0.8, 'Ground truth Frame 5', fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda34e0b-fbdf-4328-92b1-9f25048e9759",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_hat = seq.predict(X_test, verbose=0)\n",
    "visualization(y_test, Y_hat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801ce78c-20c9-4737-9cad-3a13310b21c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image\n",
    "import skimage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calculate raw normalised statistics for evaluation.\n",
    "\n",
    "Y_hat = seq.predict(X_test, verbose=0)\n",
    "\n",
    "img_dim = 16\n",
    "resi = []\n",
    "hati = []\n",
    "tesi = []\n",
    "\n",
    "count = 0\n",
    "for j in range(0, 5, 2):\n",
    "    lst = []\n",
    "    lstres = []\n",
    "    lstresidual = []\n",
    "    hat = []\n",
    "    test = []\n",
    "    for ind in range(Y_hat.shape[0]):\n",
    "\n",
    "        img_hat = Y_hat[ind][j].reshape(img_dim,img_dim).astype('float64')\n",
    "        img_test = y_test[ind][j].reshape(img_dim,img_dim)\n",
    "\n",
    "        mae = mean_absolute_error(img_hat, img_test)\n",
    "        res = np.mean(img_hat-img_test)\n",
    "        residual = img_hat-img_test\n",
    "        \n",
    "        lstresidual.append(residual)\n",
    "        lst.append(mae)\n",
    "        lstres.append(res)\n",
    "        hat.append(img_hat)\n",
    "        test.append(img_test)\n",
    "    \n",
    "    resi.append(lstresidual)\n",
    "    hati.append(hat)\n",
    "    tesi.append(test)\n",
    "    \n",
    "    lst = np.array(lst)\n",
    "    mean = np.mean(lst)\n",
    "    std = np.std(lst)\n",
    "    meansim = np.mean(lstsim)\n",
    "    stdsim = np.std(lstsim)\n",
    "    meanres = np.mean(lstres)\n",
    "    stdres = np.std(lstres)\n",
    "    \n",
    "    print(\"mean\", mean)\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f628800-401b-43d3-9d21-61ad27d75e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temporal average residual errors.\n",
    "\n",
    "avg = np.mean(resi, axis=1)\n",
    "\n",
    "f, axarr = plt.subplots(1,len(avg))\n",
    "for frame_ind in range(len(avg)):\n",
    "    \n",
    "    data_mean = 119\n",
    "    b = axarr[frame_ind].imshow(avg[frame_ind]*data_mean, interpolation='none')\n",
    "    b.axes.get_xaxis().set_visible(False)\n",
    "    b.axes.get_yaxis().set_visible(False)\n",
    "    axarr[frame_ind].title.set_text('Day ' + str(2*(frame_ind + 1)-1))\n",
    "   \n",
    "\n",
    "cbar = f.colorbar(b, ax=axarr.ravel().tolist(), orientation=\"horizontal\")\n",
    "cbar.set_label('Mean Error (Petamolecules/cm2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0f4b9-83a5-43ae-a98c-1164c8ceeed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
