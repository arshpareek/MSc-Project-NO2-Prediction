{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e565c73-5dde-4aac-8a5a-e51ee4712fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentinelsat\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade attrs\n",
    "!pip install h5netcdf\n",
    "!pip install netCDF4\n",
    "!pip install scipy\n",
    "!pip uninstall xarray -y\n",
    "!pip install xarray\n",
    "!pip install matplotlib\n",
    "!conda install -c conda-forge harp -y\n",
    "\n",
    "from sentinelsat import SentinelAPI, read_geojson, geojson_to_wkt\n",
    "import ipywidgets\n",
    "import numpy as np\n",
    "from glob import iglob\n",
    "import harp\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a831ce5-cdf4-4789-a8b6-36dbcad91386",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = SentinelAPI('s5pguest', 's5pguest', 'https://s5phub.copernicus.eu/dhus/')\n",
    "#https://s5phub.copernicus.eu/dhus/#/home\n",
    "#https://apihub.copernicus.eu/apihub\n",
    "\n",
    "footprint = geojson_to_wkt(read_geojson('./map-wide-delhi.geojson'))\n",
    "\n",
    "start_date = date(2018, 4, 30)\n",
    "\n",
    "end_date = date(2022, 7, 19)\n",
    "count = 0\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "while start_date <= end_date:\n",
    "    tmp = start_date\n",
    "    start_date += delta\n",
    "    products = api.query(footprint,\n",
    "                     date=(tmp, start_date),\n",
    "                     platformname='Sentinel-5 Precursor',\n",
    "                    producttype='L2__NO2___',\n",
    "                    limit=1)\n",
    "    if len(products) == 0:\n",
    "        count += 1\n",
    "        print(count, \"missing!!!\")\n",
    "        continue\n",
    "        \n",
    "    api.download_all(products)\n",
    "    s5p_file = ''\n",
    "    for key, value in products.items():\n",
    "        #print(key, value)\n",
    "        print(value['title'])\n",
    "        s5p_file = value['title']\n",
    "        s5p_file1 = value['title'] + '.nc'\n",
    "    \n",
    "    export_path = \"\"\n",
    "    filename = s5p_file1\n",
    "    harp_L2_L3 = harp.import_product(filename, operations=\" \\\n",
    "                                                tropospheric_NO2_column_number_density_validity>50\\\n",
    "                                                derive(tropospheric_NO2_column_number_density [Pmolec/cm2]); \\\n",
    "                                                derive(tropospheric_NO2_column_number_density_validity);\\\n",
    "                                                bin_spatial(83, 26.55, 0.05, 82, 75.1, 0.05); \\\n",
    "                                                derive(latitude {latitude}); derive(longitude {longitude})\")\n",
    "    filename = filename.split('/')[-1].replace('L2', '_wide_L3')\n",
    "    export_folder = \"{export_path}/{file}\".format(export_path=export_path, file=filename)\n",
    "    harp.export_product(harp_L2_L3, filename, file_format='netcdf')\n",
    "    \n",
    "    #no2_subset_nparray = no2_subset.to_numpy()\n",
    "    #np.save(s5p_file, no2_subset_nparray)\n",
    "    os.remove(s5p_file1)\n",
    "    #no2_subset_tensor = torch.from_numpy(no2_subset_nparray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
